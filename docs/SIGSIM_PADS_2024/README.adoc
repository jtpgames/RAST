= Improved RAST Simulator and Load Tester Components (PADS 2024)
:toc:
:toc-title: pass:[<h3>Table of Contents</h3>]

**Last change from: 21.05.2024**

**TODO: Accepted for publication at PADS 2024. Add link.**

In our paper, we explain, implement and evaluate improvements to the following components of RAST:

* Predictive Model Creator,
* Simulator,
* Load Tester.

For our evaluation, we use the https://github.com/DescartesResearch/TeaStore[TeaStore benchmarking application].
We created a GitHub fork <<teastore_fork>> and modified some parameters of their logging framework to create consistent logs especially for higher intensity workloads.

Additional experimental results not published in our paper, including the Python scripts we use for similarity calculation and the validation and prediction data acquired in our experiments, can be accessed in our Datalore notebook <<datalore_notebook>>.

== Instructions for Conducting Experiments
To conduct the experiments outlined in this paper, please follow the step-by-step instructions below:

=== System requirements
* git,
* docker-compose,
* python3.10-venv,
* python3-dev,
* openjdk-11-jre-headless

=== Preparations

* Setup TeaStore according to the https://github.com/jtpgames/RAST/blob/main/docs/TeaStore/Deployment.adoc#setup-teastore[instructions].
* Clone this repository. Make sure, to pull all git submodels as well:
    . `git clone https://github.com/jtpgames/RAST.git`
    . `cd RAST`
    . `./pull_all_submodules.sh`

=== Workflow
Recommended workflow (for terminal users):

. Open your terminal and use a terminal multiplexer such as tmux to create four sessions. We will refer to these sessions by numbers:
    * Session (1): This session will be used to start the TeaStore or the Simulator. Navigate to the respective folder within the cloned repositories.
    * Session (2): This session will be used to start the Load Test. Navigate to the `locust_scripts` folder.
    * Session (3): This session will be used to make code changes to the `offical_teastore_locustfile.py` file, allowing you to modify the load intensity profile. 
      Navigate to the `locust_scripts/locust` folder and open the file using a text editor of your choice (e.g., Vim or Emacs).
    * Session (4): This session will be used to make code changes to the `teastore.kt` file, enabling you to modify the predictive model. 
      Navigate to the Simulators folder and open the file.
. In Session (1), start the TeaStore or the Simulator based on the measurements you wish to acquire.
   For the purpose of this explanation, we will focus on starting the Simulator. 
   Navigate to your local Simulator folder and execute the command `./gradlew run`. 
   If successful, you will see the following line printed on the console: `INFO ktor.application - Responding at http://0.0.0.0:8081`. 
   To terminate the Simulator, press `Ctrl + C`.
. In Session (2):
..  (Recommended):
...     Create a python virtual environment in a directory called `venv`, e.g., `python3 -m venv venv`
...     Run the command `source activate_venv.sh` to activate the Python virtual environment (venv).
...     Run `pip install -r requirements.txt`
..  Execute `./start_teastore_loadtest.sh` to initiate the load test.
    This repository uses a low load intensity by default.
    The load test will automatically conclude after approximately two minutes.
..  Clean the folder by executing `./delete_results.sh`.
. In Session (4), you can now examine the `teastore_simulation.log` file.
  This file contains simulated processing times generated by the predictive model, among other relevant information.
. To modify the load intensity profile,
  navigate to Session (3) and locate the `StagesShape` class within the `offical_teastore_locustfile.py` file.
  Look for the line `load_intensity_profile: LoadIntensityProfile = LoadIntensityProfile.LOW`.
  Set `load_intensity_profile` to your desired value.
. To modify the predictive model,
  navigate to Session (4) and follow the instructions in the README.md file within the Simulators repository.

=== Prediction data
The prediction data as described in the paper was acquired by running a load test against the simulator with each load intensity profile. In between each load test, we copied the resulting teastore_simulation.log file and renamed it accordingly. After acquiring a log file for each load intensity profile, we used our `ResultComparer` found in our Datalore notebook <<datalore_notebook>>. We recommend to take a look at our datalore notebook or the snapshot archive in the Artefact Submission folder to see the recommended naming and structure.

=== Validation data
The validation data is available in our Datalore notebook <<datalore_notebook>>.
Acquiring the validation data from TeaStore is a more complex process involving downloading kieker logs, transforming them and storing into an SQLite database.
The instructions https://github.com/jtpgames/RAST/blob/main/docs/TeaStore/ETL.adoc[here] explain this process.
The validation data is acquired in a similar fashion as the prediction data, i.e., running a load test, creating a database and repeating for each load intensity profile. Again, we recommend to take a look at our datalore notebook or the snapshot archive to see the structure.

== Artefact Submission Inventory

* Datalore notebook(https://datalore.jetbrains.com/notebook/6K6VkECuLMtN5t5nSYg6WK/TVGp1egwDQlwI19astdVlM): Includes instructions, our measurements and the Python code we use for similarity calculation. To access the datalore notebook (similar to a Jupyter notebook) creation of a free account is required.
* RAST_TeaStore_Simulation_Similarity.zip: Exported Datalore notebook snapshot 21.05.2024. The folder `TeaStoreResultComparisonData` includes both the Validation Data and Prediction Data we used in our paper (the datalore notebook above contains a greater set of Prediction Data for models we did not mention in our paper).
* similarity_scores.csv: File created from the ResultComparer Python script found in our Datalore notebook.
* similarity_scores.ods: File created from the similarity_scores.csv file using LibreOffice. Includes all formulaes to assess the experimental results as well as the figures found in the paper. Also includes results and figures not found in the paper.
* Figures: Includes all figures generated using the similarity_scores.ods file.

[bibliography]
== References

* [[[teastore_fork]]](https://github.com/jtpgames/TeaStore)
* [[[simulator_repo]]](https://github.com/jtpgames/Simulators)
* [[[datalore_notebook]]](https://datalore.jetbrains.com/notebook/6K6VkECuLMtN5t5nSYg6WK/TVGp1egwDQlwI19astdVlM)

